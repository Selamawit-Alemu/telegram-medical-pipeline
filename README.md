ğŸ©º Telegram Medical Data Pipeline

An end-to-end data engineering project that collects, stores, transforms, and models Telegram messages and media from Ethiopian medical channels. Designed for production, this pipeline follows best practices using modern data tooling and a modular architecture.
ğŸ“Œ Project Overview
Component	Tool / Technology
ğŸ“¥ Data Ingestion	Python + Telethon
ğŸ—ƒï¸ Raw Storage	Local JSON + image files
ğŸ›¢ï¸ Data Warehouse	PostgreSQL
ğŸ§± Data Transformation	dbt (Data Build Tool)
âœ… Data Validation	dbt built-in + custom tests
âš™ï¸ Orchestration (Next)	Dagster
ğŸ§  Enrichment (Next)	YOLOv8 for image detection
ğŸš€ API (Planned)	FastAPI
âœ… Completed Tasks
âœ… Task 0: Project Setup

    Organized modular project layout

    Configured .env for secrets and connection variables

    Set up requirements.txt and Python virtual environment

    Initialized Git and version control

    Added .gitignore (excludes target/, __pycache__/, virtual env, etc.)

âœ… Task 1: Data Collection

    Used Telethon to scrape messages from Telegram medical channels

    Incremental scraping using metadata/last_scraped.json

    Saved raw JSON messages and images in data/raw/telegram_messages/YYYY-MM-DD/

    Enabled rich logging with loguru

âœ… Task 2: Data Modeling & Transformation

    Loaded scraped messages into PostgreSQL using load_to_postgres.py

    Initialized telegram_dbt/ as a dbt project

    Created:

        stg_telegram_messages (staging layer)

        dim_channels, dim_dates (dimension tables)

        fct_messages (fact table)

    Implemented star schema with primary/foreign key constraints

    Applied 14 dbt tests: not_null, unique, custom test no_null_text_with_media, and future date check

    Generated docs using dbt docs generate

ğŸ—‚ Project Structure

telegram-medical-pipeline/
    â”œâ”€â”€ data/
    â”‚   â””â”€â”€ raw/telegram_messages/YYYY-MM-DD/channel_data.json
    â”œâ”€â”€ metadata/
    â”‚   â””â”€â”€ last_scraped.json
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ telegram_scraper.py
    â”‚   â””â”€â”€ load_to_postgres.py
    â”œâ”€â”€ telegram_dbt/
    â”‚   â”œâ”€â”€ models/
    â”‚   â”‚   â”œâ”€â”€ staging/stg_telegram_messages.sql
    â”‚   â”‚   â””â”€â”€ marts/
    â”‚   â”‚       â”œâ”€â”€ dim_channels.sql
    â”‚   â”‚       â”œâ”€â”€ dim_dates.sql
    â”‚   â”‚       â””â”€â”€ fct_messages.sql
    â”‚   â”œâ”€â”€ tests/no_null_text_with_media.sql
    â”‚   â””â”€â”€ dbt_project.yml
    â”œâ”€â”€ .env
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ README.md
    â””â”€â”€ .gitignore

## âš™ï¸ Local Setup
## âš ï¸ Important Notes

- The `target/` folder is included in `.gitignore` because it contains auto-generated dbt build files and docs. To generate this folder locally, run:


    cd telegram_dbt
    dbt run
    dbt test
    dbt docs generate

1. Clone the repository

    git clone https://github.com/YOUR_USERNAME/telegram-medical-pipeline.git
    cd telegram-medical-pipeline

2. Set up Python environment

    python -m venv venv
    source venv/bin/activate  # Windows: .\venv\Scripts\activate
    pip install -r requirements.txt

3. Configure PostgreSQL

        Create a PostgreSQL database and user.

        Update .env with connection details.

4. Run the Scraper

    python src/telegram_scraper.py

5. Load to PostgreSQL

    python src/load_to_postgres.py

6. Transform with dbt

    cd telegram_dbt
    dbt run
    dbt test

7. View dbt Docs

    dbt docs generate
    dbt docs serve

ğŸ§ª Testing Summary

    14 dbt tests implemented:

        not_null, unique tests on keys

        Custom test: no_null_text_with_media

        Logic test: no_future_dates in fct_messages

    All tests pass or catch data integrity issues early

